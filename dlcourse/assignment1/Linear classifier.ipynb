{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d)\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.006760443547122"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(int)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(float)\n",
    "target_index = np.ones(batch_size, dtype=int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=10, learning_rate=1e-3, batch_size=300, reg=1e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe578a7f0d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.15\n",
      "Accuracy after training for 100 epochs:  0.146\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-3, batch_size=300, reg=1e1)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best validation accuracy achieved: 0.254000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 300\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for reg in reg_strengths:\n",
    "        classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "        classifier.fit(train_X, train_y, batch_size=batch_size, \n",
    "                       learning_rate=learning_rate, reg=reg, epochs=num_epochs)\n",
    "        pred = classifier.predict(val_X)\n",
    "        accuracy = multiclass_accuracy(pred, val_y)\n",
    "        if best_val_accuracy == None or best_val_accuracy < accuracy:\n",
    "            best_classifier = classifier\n",
    "            best_val_accuracy = accuracy\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear softmax classifier test set accuracy: 0.210000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
